{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66027888",
   "metadata": {},
   "source": [
    "# Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d90c207b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perfomance\n",
      "{'VOLUMETRIA_MENSAL': {'2017-01': 58, '2017-02': 55, '2017-03': 62, '2017-04': 49, '2017-05': 67, '2017-06': 63, '2017-07': 74, '2017-08': 72}, 'AUC_ROC': 0.5751748251748252}\n",
      "aderencia\n",
      "{'ks_statistic': 0.0019183285403152617, 'p_value': 0.999315259526548}\n",
      "{'ks_statistic': 0.021736133923338036, 'p_value': 5.0522344570608844e-14}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "# Testa performance\n",
    "print('perfomance')\n",
    "\n",
    "with open(\"monitoring/batch_records.json\", \"r\") as f:\n",
    "    records = json.load(f)\n",
    "\n",
    "resp = requests.post(\"http://localhost:8001/v1/performance\", json=records)\n",
    "print(resp.json())\n",
    "\n",
    "# Testa aderência\n",
    "print('aderencia')\n",
    "\n",
    "# base a)\n",
    "resp = requests.post(\"http://localhost:8001/v1/aderencia\", json={\"dataset_path\": \"datasets/credit_01/train.gz\"})\n",
    "print(resp.json())\n",
    "\n",
    "# base b)\n",
    "resp = requests.post(\"http://localhost:8001/v1/aderencia\", json={\"dataset_path\": \"datasets/credit_01/oot.gz\"})\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d8ecfd",
   "metadata": {},
   "source": [
    "# Observações sobre o modelo e sua perfomance:\n",
    "\n",
    "- a curva ROC do modelo no dataset de train teve um roc mediano, então talvez seja possível encontrar algoritmos que funcionam melhor pra esse problema\n",
    "- no primeiro dataset pra aderencia, p-value muito próximo de 1 e ks muito próximo de 0, então não rejeitamos a hipótese que as distribuições comparadas seguem a mesma distribuição então podemos considerar que a base usada nesse teste está próxima da base usada no treinamento do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4678f4",
   "metadata": {},
   "source": [
    "# Perguntas\n",
    "\n",
    "### Se quisermos expandir o monitoramento para todos os modelos atualmente em produção, você acha que pode dar algum problema caso haja muitas requisições simultâneas ao mesmo endpoint da API? O que podemos fazer neste caso?\n",
    "Sim, pode haver problemas de performance, como lentidão ou falhas dependendo de vários fatores como o servidor ou o modelo pra avaliar. Pra ajudar a mitigar isso, podemos carregar o modelo uma única vez na inicialização do app, evitando reprocessamento. Podemos também usar um cache para requisições repetidas ou de debugação.\n",
    "\n",
    "### Que outro problema um modelo de machine learning pode enfrentar em produção, que você ache interessante monitorar?\n",
    "existem alguns que podem surgir por inumeros fatores:\n",
    "- Um drift nos dados conforme novos dados aparecem pro modelo\n",
    "- Pode surgir um algoritmo ou passo de processamento de dados que aprimore a acurácia do modelo e precisaria que atualiza-lo\n",
    "- O modelo pode, também, performar mal no mundo real mesmo tendo uma acurácia com dados de teste. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Neurodesafio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
